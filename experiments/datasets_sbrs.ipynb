{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset preparation\n",
    "Background: I'd like to run the RecBole algorithms in a session-based task on 4 datasets, and compare results to what's published in the following papers:\n",
    "- Evaluation of Session-based Recommendation Algorithms, Ludewig et al 2018\n",
    "- Empirical Analysis of Session-Based Recommendation Algorithms, Ludewig et al 2020\n",
    "- A survey on session-based recommender systems, Wang et al 2021\n",
    "\n",
    "The first 2 papers have also published their code in the session-rec framework. they also have the datasets to download.\n",
    "All 3 papers are aligned on the datasets: \n",
    "![img](SBRS_datasets.png)\n",
    "\n",
    "\n",
    "the goal is to understand what is needed to create the following SBRS version of the following datasets: \n",
    "- RetailRocket\n",
    "- RSC15\n",
    "- DIGINETICA - we already have `diginetica-session` as `.inter` file. need to compare the characteristics to the published one\n",
    "- NowPlaying - we already have `nowplaying-session` as `.inter` file. we cant generate it from raw in `session-rec` because we dont have the corresponding preprocessing script\n",
    "- Tmall - we already have `tmall-session` as `.inter` file. we cant generate it from raw in `session-rec` due to error on the preprocessing script.\n",
    "\n",
    "\n",
    "\n",
    "RecBole has DIGINETICA and NowPlaying in a `session based` version. need to compare the characteristics to `session-rec` version "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "from recbole.config import Config\n",
    "from recbole.data import create_dataset\n",
    "from recbole.data.utils import get_dataloader\n",
    "from recbole.utils import init_logger, init_seed, get_model, get_trainer, set_color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class Arguments:\n",
    "    model:str = 'GRU4Rec'\n",
    "    dataset:str = 'diginetica-session'\n",
    "    validation: bool = 'False'      # Whether evaluating on validation set (split from train set), otherwise on test set.\n",
    "    valid_portion: float = 0.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_dict_sess = {\n",
    "    'USER_ID_FIELD': 'session_id',\n",
    "    'load_col': None,\n",
    "    'neg_sampling': None,\n",
    "    'benchmark_filename': ['train', 'test'],\n",
    "    'alias_of_item_id': ['item_id_list'],\n",
    "    'topk': [20],\n",
    "    'metrics': ['Recall', 'MRR'],\n",
    "    'valid_metric': 'MRR@20',\n",
    "    'gpu_id': 0\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DIGINETICA\n",
    "Lets start by comparing `diginetica-session` to what we have in `session-rec` and the above table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recbole"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### session based\n",
    "There was a script that is not given in the repository that reads the raw data input file as downloaded from diginetica and converts it to `.inter` file\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Arguments(dataset='diginetica-session')\n",
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Config(model=args.model, dataset=f'{args.dataset}', config_dict=config_dict_sess)\n",
    "config.final_config_dict['data_path'] = os.path.join(os.path.dirname(os.getcwd()),config.final_config_dict['data_path'])\n",
    "config.final_config_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# called from the main script and performs a set of operations to load the .inter file to dataframe\n",
    "digi_recbole_sess = create_dataset(config)\n",
    "digi_recbole_sess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "digi_recbole_sess_inter_df=digi_recbole_sess.inter_feat\n",
    "digi_recbole_sess_inter_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "digi_recbole_sess_inter_df.session_id.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "digi_recbole_sess_inter_df.loc[digi_recbole_sess_inter_df.session_id==1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(digi_recbole_sess_inter_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "its not clear what is `item_id` in this file. is it the last item in the session (where all the rest are in `item_id_list`) ?\n",
    "\n",
    "the script for generating the `.inter` file of the sessionized version is not provided"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step into `create_dataset`\n",
    "lets look at the input file first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(config.final_config_dict['data_path'])\n",
    "os.listdir(config.final_config_dict['data_path'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "when calling `create_dataset` it understand that the dataset class is `SequentialDataset` and defines this class, calling its constructor.  \n",
    "the consstructor calls its `super` class (`Dataset`) constructor that calls eventually loads the above files to dataframe using the following:  \n",
    "`Dataset._load_data()` --> `Dataset._load_inter_feat` --> `Dataset._load_feat`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_inter_df=pd.read_csv(os.path.join(config.final_config_dict['data_path'],'diginetica-session.train.inter'),delimiter='\\t')\n",
    "tr_inter_df.head(15)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and this is the structure of the file we need to generate.\n",
    "the idea is to use the pre-processing of `session-rec` which generates the files in the folder `/home/gkoren2/datasets/recsys/seq_recsys_datasets/diginetica/prepared`:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_inter_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prep_srec_path = '/home/gkoren2/datasets/recsys/seq_recsys_datasets/diginetica/prepared'\n",
    "os.listdir(prep_srec_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we want to do the following conversion:\n",
    "- `train-item-views_train_full.txt` --> `diginetica-session.train.inter`\n",
    "- `train-item-views_test.txt` --> `diginetica-session.test.inter`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "digi_args = Arguments(dataset='diginetica')\n",
    "digi_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "digi_config_dict= {\n",
    "        'USER_ID_FIELD': 'session_id',\n",
    "        'load_col': None,       # load all columns. dont filter anything\n",
    "        'neg_sampling': None,\n",
    "        # 'benchmark_filename': ['train', 'test'],\n",
    "        # 'alias_of_item_id': ['item_id_list'],\n",
    "        'eval_args':{\n",
    "            'group_by': 'user',\n",
    "            'order': 'TO',\n",
    "            'split':{'LS': 'test_only'},\n",
    "            'mode': 'uni100'},\n",
    "        'topk': [20],\n",
    "        'metrics': ['Recall', 'MRR'],\n",
    "        'valid_metric': 'MRR@20'\n",
    "    }\n",
    "digi_config = Config(model=digi_args.model, dataset=f'{digi_args.dataset}', config_dict=digi_config_dict)\n",
    "digi_config.final_config_dict['data_path'] = os.path.join(os.path.dirname(os.getcwd()),digi_config.final_config_dict['data_path'])\n",
    "digi_config.final_config_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "digi_recbole_raw = create_dataset(digi_config)\n",
    "digi_recbole_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "digi_recbole_raw_inter_df = digi_recbole_raw.inter_feat\n",
    "digi_recbole_raw_inter_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "digi_recbole_raw_inter_df['number of times'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "digi_recbole_raw_inter_df.session_id.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(digi_recbole_sess_inter_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## session-rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = '/home/gkoren2/datasets/recsys/seq_recsys_datasets/'\n",
    "datapath_raw = os.path.join(dataset_path,'diginetica','raw')\n",
    "os.listdir(datapath_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "digi_srec_raw = pd.read_csv(os.path.join(datapath_raw,'train-item-views.csv'),delimiter=';')\n",
    "digi_srec_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(digi_srec_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "digi_srec_raw.sessionId.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(digi_srec_raw.itemId.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### preprocessing with `run_preprocessing.py`\n",
    "using 2 configurations:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "/home/gkoren2/study/git/guyk1971/session-rec/conf/myconf/prep_digi_sb_s.yml\n",
    "```yml\n",
    "type: single # single|window\n",
    "mode: session_based # session_based | session_aware\n",
    "preprocessor: diginetica # dataset (folder) name\n",
    "data:\n",
    "  folder: /home/gkoren2/datasets/recsys/seq_recsys_datasets/diginetica/raw/\n",
    "  prefix: train-item-views\n",
    "\n",
    "filter:\n",
    "  min_item_support: 5\n",
    "  min_session_length: 2\n",
    "\n",
    "params:\n",
    "  days_test: 7\n",
    "\n",
    "output:\n",
    "  folder: /home/gkoren2/datasets/recsys/seq_recsys_datasets/diginetica/prepared/\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "/home/gkoren2/study/git/guyk1971/session-rec/conf/myconf/prep_digi_sb_w.yml\n",
    "```yml\n",
    "type: window # single|window\n",
    "mode: session_based # session_based | session_aware\n",
    "preprocessor: diginetica #\n",
    "data:\n",
    "  folder: /home/gkoren2/datasets/recsys/seq_recsys_datasets/diginetica/raw/\n",
    "  prefix: train-item-views\n",
    "\n",
    "filter:\n",
    "  min_item_support: 5\n",
    "  min_session_length: 2\n",
    "\n",
    "params:\n",
    "  days_test: 7\n",
    "  days_train: 25 #only window\n",
    "  num_slices: 5 #only window\n",
    "  days_offset: 45 #only window\n",
    "  days_shift: 18 #only window\n",
    "\n",
    "output:\n",
    "  folder: /home/gkoren2/datasets/recsys/seq_recsys_datasets/diginetica/slices/\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "so now we have txt files that we can read and convert to atomic files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tree /home/gkoren2/datasets/recsys/seq_recsys_datasets/diginetica"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "how do I read it to dataframe ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting from session-rec prepared to RecBole .inter \n",
    "we can see above the structure of the `.inter` file. this is our target.   \n",
    "these are our 'input' files:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "prep_srec_path = '/home/gkoren2/datasets/recsys/seq_recsys_datasets/diginetica/prepared'\n",
    "os.listdir(prep_srec_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we want to do the following conversion:\n",
    "- `train-item-views_train_full.txt` --> `diginetica-session.train.inter`\n",
    "- `train-item-views_test.txt` --> `diginetica-session.test.inter`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Draft Sandbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_file='train-item-views_train_full'\n",
    "\n",
    "train_df = pd.read_csv(os.path.join(prep_srec_path,src_file+'.txt'), sep='\\t')\n",
    "train_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_file='train-item-views_test'\n",
    "\n",
    "tst_df = pd.read_csv(os.path.join(prep_srec_path,src_file+'.txt'), sep='\\t')\n",
    "tst_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note that the itemIDs are not sequential. we need to make them such\n",
    "print(len(train_df.ItemId.value_counts()))\n",
    "train_df.ItemId.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(tst_df.ItemId.value_counts()))\n",
    "tst_df.ItemId.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_col = ['SessionId', 'ItemId']\n",
    "trdf=train_df[src_col]\n",
    "tsdf=tst_df[src_col]\n",
    "trdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trdf.ItemId.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set(tsdf.ItemId.unique()) - set(trdf.ItemId.unique())\n",
    "len(set(tsdf.ItemId.unique()).union(set(trdf.ItemId.unique())))\n",
    "# set(trdf.ItemId.unique()).add(set(tsdf.ItemId.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trg2src_id={k+1:v for k, v in zip(range(len(trdf.ItemId.unique())),trdf.ItemId.unique())}\n",
    "src2trg_id={v:k for k,v in trg2src_id.items()}\n",
    "len(trg2src_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trdf.ItemId=trdf.ItemId.map(src2trg_id)\n",
    "tsdf.ItemId=tsdf.ItemId.map(src2trg_id)     # assuming no tst items that are absent from training set\n",
    "trdf.ItemId.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trdf.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbs=trdf.groupby('SessionId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# since we break each session to several subsessions, we need to know how many subsessions we'll have in total.\n",
    "# this will save us the copy in concatenating by allocating the dataframe from advance\n",
    "# session with N elements will be broken to N-1 sessions\n",
    "# so to understand the total number of subsessions we need to summarize the Ns-1 (the size of the session-1):\n",
    "gbs.size().sum() - len(gbs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tgt_col=['session_id:token', 'item_id_list:token_seq', 'item_id:token']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_session2(sess_df,sid):\n",
    "    iid = sess_df.ItemId.values\n",
    "    iids=[(str(iid[:i])[1:-1],str(iid[i])) for i in reversed(range(1,len(iid)))]\n",
    "    iidfd=dict()\n",
    "    iidfd.update({'session_id:token':[sid+i+1 for i in range(len(iids))]})\n",
    "    iidfd.update({'item_id_list:token_seq':[i[0] for i in iids]})\n",
    "    iidfd.update({'item_id:token':[i[1] for i in iids]})\n",
    "    iidfs=pd.DataFrame(iidfd)\n",
    "    \n",
    "    return iidfs,iidfd['session_id:token'][-1]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "maxlen=0\n",
    "for g in tqdm(list(gbs.groups)[100]):\n",
    "    leng=len(gbs.get_group(g))\n",
    "    if leng>maxlen:\n",
    "        maxlen=leng\n",
    "\n",
    "print(maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(gbs.groups.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rbdf=[]\n",
    "# rbdf=pd.DataFrame(columns=tgt_col)\n",
    "sid=0\n",
    "for grp in tqdm(gbs.groups):\n",
    "    sub_rbdf,sid=process_session2(gbs.get_group(grp),sid)\n",
    "    rbdf.append(sub_rbdf)\n",
    "rbdf=pd.concat(rbdf,ignore_index=True)\n",
    "rbdf.head(30)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rbdf=[]\n",
    "rbdf=pd.DataFrame(columns=tgt_col)\n",
    "sid=0\n",
    "for grp in tqdm(gbs.groups):\n",
    "    sub_rbdf,sid=process_session2(gbs.get_group(grp),sid)\n",
    "    rbdf=pd.concat([rbdf,sub_rbdf],ignore_index=True)\n",
    "rbdf.head(30)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Final Conversion Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_session(sess_df,sid):\n",
    "    iid = sess_df.ItemId.values\n",
    "    iids=[(str(iid[:i])[1:-1],str(iid[i])) for i in reversed(range(1,len(iid)))]\n",
    "    iidfd=dict()\n",
    "    iidfd.update({'session_id:token':[sid+i+1 for i in range(len(iids))]})\n",
    "    iidfd.update({'item_id_list:token_seq':[i[0] for i in iids]})\n",
    "    iidfd.update({'item_id:token':[i[1] for i in iids]})\n",
    "    iidfs=pd.DataFrame(iidfd)\n",
    "    \n",
    "    return iidfs,iidfd['session_id:token'][-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_df(srec_df,n_sess):\n",
    "    gbs=srec_df.groupby('SessionId')\n",
    "    recbole_col=['session_id:token', 'item_id_list:token_seq', 'item_id:token']\n",
    "    rbdf=[]\n",
    "    sid=0\n",
    "    n_sess = n_sess or len(gbs.groups)\n",
    "    for grp in tqdm(list(gbs.groups)[:n_sess]):\n",
    "        sub_rbdf,sid=process_session(gbs.get_group(grp),sid)\n",
    "        rbdf.append(sub_rbdf)\n",
    "    rbdf=pd.concat(rbdf,ignore_index=True)\n",
    "    return rbdf \n",
    "\n",
    "\n",
    "def convert_srec_to_recbole(srec_train_filename,srec_test_filename, inter_train_filename,inter_test_filename,n_sess=None):\n",
    "    srec_train_df = pd.read_csv(os.path.join(prep_srec_path,srec_train_filename+'.txt'), sep='\\t')\n",
    "    srec_test_df = pd.read_csv(os.path.join(prep_srec_path,srec_test_filename+'.txt'), sep='\\t')\n",
    "    srec_col = ['SessionId', 'ItemId']\n",
    "    srec_trn_df=srec_train_df[srec_col]\n",
    "    srec_tst_df=srec_test_df[srec_col]\n",
    "    if (set(srec_test_df.ItemId.unique())-set(srec_train_df.ItemId.unique())):\n",
    "        print(\"Warning: there are new items in the test set \")\n",
    "        srec_ItemId=set(srec_train_df.ItemId.unique()).union(set(srec_test_df.ItemId.unique()))\n",
    "    else:\n",
    "        srec_ItemId=set(srec_train_df.ItemId.unique())\n",
    "    # remap item_id to be sequential from 1 to N\n",
    "    trg2src_id={k+1:v for k, v in zip(range(len(srec_ItemId)),srec_ItemId)}\n",
    "    src2trg_id={v:k for k,v in trg2src_id.items()}\n",
    "    srec_train_df.ItemId=srec_train_df.ItemId.map(src2trg_id)\n",
    "    srec_test_df.ItemId=srec_test_df.ItemId.map(src2trg_id)\n",
    "    print(f'generating {inter_train_filename}:')\n",
    "    rbdf=transform_df(srec_train_df,n_sess)\n",
    "    rbdf.to_csv(inter_train_filename,sep='\\t',index=None)\n",
    "\n",
    "    print(f'generating {inter_test_filename}:')\n",
    "    rbdf=transform_df(srec_test_df,n_sess)\n",
    "    rbdf.to_csv(inter_test_filename,sep='\\t',index=None)\n",
    "\n",
    "    print('Done')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "srec_train_filename='train-item-views_train_full'\n",
    "inter_train_filename='./diginetica-sess.train.inter'\n",
    "\n",
    "srec_test_filename='train-item-views_test'\n",
    "inter_test_filename='./diginetica-sess.test.inter'\n",
    "\n",
    "convert_srec_to_recbole(srec_train_filename,srec_test_filename,inter_train_filename,inter_test_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tmall\n",
    "\n",
    "<font color='red'> ERROR: Cant preprocess raw file in `session-rec`. problem with the preprocessing script </font>  \n",
    "\n",
    "\n",
    "now that we successfully converted DIGINETICA from `session-rec` to diginetica-sess (`.inter` files) for Recbole, lets do it again for another dataset that already has a ready made `-session.inter` file.\n",
    "\n",
    "the stages are as follows:\n",
    "1. Read the RecBole .inter file and check its characteristics - for reference later\n",
    "1. Read the session-rec file and compare its characteristics to the table at the head of the notebook. should be the same\n",
    "1. Convert the session-rec file to `-sess.inter` file\n",
    "1. read the new `-sess.inter` file and compare to the `-session.inter`\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the import section above \n",
    "pd.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read RecBole file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Arguments(dataset='tmall-session')\n",
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Config(model=args.model, dataset=f'{args.dataset}', config_dict=config_dict_sess)\n",
    "config.final_config_dict['data_path'] = os.path.join(os.path.dirname(os.getcwd()),config.final_config_dict['data_path'])\n",
    "config.final_config_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(config.final_config_dict['data_path'])\n",
    "os.listdir(config.final_config_dict['data_path'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_inter_df=pd.read_csv(os.path.join(config.final_config_dict['data_path'],'tmall-session.train.inter'),delimiter='\\t')\n",
    "tr_inter_df.head(30)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### using `create_dataset` to read the .inter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# called from the main script and performs a set of operations to load the .inter file to dataframe\n",
    "nowp_session = create_dataset(config)\n",
    "nowp_session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inter_df=nowp_session.inter_feat\n",
    "inter_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inter_df.item_length.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "note that the IDs of the items were remapped to be sequential according to the order they appear in the `item_id` column, thus we see the numbers are running up in this column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## preprocess raw file according to session-rec preprocess\n",
    "as done before, we need to create a preprocess configuration file for the preprocessing in the `session-rec` framework and run the preprocessing.\n",
    "\n",
    "we can use the preprocessing script to prepare the files as we want, according to their protocols.\n",
    "\n",
    "within the session-rec framework, I've created the following configuration file for the preprocessing:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "/home/gkoren2/study/git/guyk1971/session-rec/conf/myconf/prep_tmal_sb_s.yml\n",
    "```yml\n",
    "type: single # single|window\n",
    "mode: session_based # session_based | session_aware\n",
    "preprocessor: tmall # dataset (folder) name\n",
    "data:\n",
    "  folder: /home/gkoren2/datasets/recsys/seq_recsys_datasets/tmall/raw/\n",
    "  prefix: dataset15\n",
    "\n",
    "filter:\n",
    "  min_item_support: 5\n",
    "  min_session_length: 2\n",
    "\n",
    "params:\n",
    "  days_test: 7\n",
    "\n",
    "output:\n",
    "  folder: /home/gkoren2/datasets/recsys/seq_recsys_datasets/tmall/prepared/\n",
    "```\n",
    "\n",
    "<font color='red'> it doesnt run. need to debug it in the session-rec framework. compare to the diginetica preprocessing </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prep_srec_path = '/home/gkoren2/datasets/recsys/seq_recsys_datasets/diginetica/prepared'\n",
    "os.listdir(prep_srec_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RetailRocket  \n",
    "the stages are as follows:\n",
    "1. Read the RecBole .inter file and check its characteristics - for reference later\n",
    "1. Read the session-rec file and compare its characteristics to the table at the head of the notebook. should be the same\n",
    "1. Convert the session-rec file to `-sess.inter` file\n",
    "1. read the new `-sess.inter` file and compare to the `-session.inter`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.4.3'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run the import section above \n",
    "pd.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## preprocess raw file according to session-rec preprocess\n",
    "as done before, we need to create a preprocess configuration file for the preprocessing in the `session-rec` framework and run the preprocessing.\n",
    "\n",
    "we can use the preprocessing script to prepare the files as we want, according to their protocols.\n",
    "\n",
    "within the session-rec framework, I've created the following configuration file for the preprocessing:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "/home/gkoren2/study/git/guyk1971/session-rec/conf/myconf/prep_retailrocket_sb_s.yml\n",
    "```yml\n",
    "type: single # single|window\n",
    "mode: session_based # session_based | session_aware\n",
    "preprocessor: retailrocket # dataset (folder) name\n",
    "data:\n",
    "  folder: /home/gkoren2/datasets/recsys/seq_recsys_datasets/retailrocket/\n",
    "  prefix: events\n",
    "\n",
    "filter:\n",
    "  min_item_support: 5\n",
    "  min_session_length: 2\n",
    "\n",
    "params:\n",
    "  days_test: 7\n",
    "\n",
    "output:\n",
    "  folder: /home/gkoren2/datasets/recsys/seq_recsys_datasets/retailrocket/prepared/\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['events_test.txt', 'events_orig.hdf', 'events_train_full.txt']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prep_srec_path = '/home/gkoren2/datasets/recsys/seq_recsys_datasets/retailrocket/prepared'\n",
    "os.listdir(prep_srec_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we want to do the following conversion:\n",
    "- `events_train_full.txt` --> `retailrocket-sess.train.inter`\n",
    "- `events_test.txt` --> `retailrocket-sess.test.inter`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure to run the conversion code cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating ./retailrocket-sess.train.inter:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78bf54802157401b8eb5a0db9b97280d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/294437 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating ./retailrocket-sess.test.inter:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f2cba5bfe8f4fb38646a952a3945308",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12197 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "srec_train_filename='events_train_full'\n",
    "inter_train_filename='./retailrocket-sess.train.inter'\n",
    "\n",
    "srec_test_filename='events_test'\n",
    "inter_test_filename='./retailrocket-sess.test.inter'\n",
    "\n",
    "convert_srec_to_recbole(srec_train_filename,srec_test_filename,inter_train_filename,inter_test_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the resulting .inter file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Arguments(model='GRU4Rec', dataset='retailrocket-sess', validation='False', valid_portion=0.1)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args = Arguments(dataset='retailrocket-sess')\n",
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gpu_id': 0,\n",
       " 'use_gpu': True,\n",
       " 'seed': 2020,\n",
       " 'state': 'INFO',\n",
       " 'reproducibility': True,\n",
       " 'data_path': '/home/gkoren2/study/git/guyk1971/RecBole/dataset/retailrocket-sess',\n",
       " 'checkpoint_dir': 'saved',\n",
       " 'show_progress': True,\n",
       " 'save_dataset': False,\n",
       " 'dataset_save_path': None,\n",
       " 'save_dataloaders': False,\n",
       " 'dataloaders_save_path': None,\n",
       " 'log_wandb': False,\n",
       " 'wandb_project': 'recbole',\n",
       " 'epochs': 300,\n",
       " 'train_batch_size': 2048,\n",
       " 'learner': 'adam',\n",
       " 'learning_rate': 0.001,\n",
       " 'neg_sampling': None,\n",
       " 'eval_step': 1,\n",
       " 'stopping_step': 10,\n",
       " 'clip_grad_norm': None,\n",
       " 'weight_decay': 0.0,\n",
       " 'loss_decimal_place': 4,\n",
       " 'require_pow': False,\n",
       " 'eval_args': {'split': {'LS': 'valid_and_test'},\n",
       "  'order': 'TO',\n",
       "  'mode': 'full',\n",
       "  'group_by': 'user'},\n",
       " 'repeatable': True,\n",
       " 'metrics': ['Recall', 'MRR'],\n",
       " 'topk': [20],\n",
       " 'valid_metric': 'MRR@20',\n",
       " 'valid_metric_bigger': True,\n",
       " 'eval_batch_size': 4096,\n",
       " 'metric_decimal_place': 4,\n",
       " 'embedding_size': 64,\n",
       " 'hidden_size': 128,\n",
       " 'num_layers': 1,\n",
       " 'dropout_prob': 0.3,\n",
       " 'loss_type': 'CE',\n",
       " 'field_separator': '\\t',\n",
       " 'seq_separator': ' ',\n",
       " 'USER_ID_FIELD': 'session_id',\n",
       " 'ITEM_ID_FIELD': 'item_id',\n",
       " 'RATING_FIELD': 'rating',\n",
       " 'TIME_FIELD': 'timestamp',\n",
       " 'seq_len': None,\n",
       " 'LABEL_FIELD': 'label',\n",
       " 'threshold': None,\n",
       " 'NEG_PREFIX': 'neg_',\n",
       " 'load_col': None,\n",
       " 'unload_col': None,\n",
       " 'unused_col': None,\n",
       " 'additional_feat_suffix': None,\n",
       " 'rm_dup_inter': None,\n",
       " 'val_interval': None,\n",
       " 'filter_inter_by_user_or_item': True,\n",
       " 'user_inter_num_interval': '[0,inf)',\n",
       " 'item_inter_num_interval': '[0,inf)',\n",
       " 'alias_of_user_id': None,\n",
       " 'alias_of_item_id': ['item_id_list'],\n",
       " 'alias_of_entity_id': None,\n",
       " 'alias_of_relation_id': None,\n",
       " 'preload_weight': None,\n",
       " 'normalize_field': None,\n",
       " 'normalize_all': None,\n",
       " 'ITEM_LIST_LENGTH_FIELD': 'item_length',\n",
       " 'LIST_SUFFIX': '_list',\n",
       " 'MAX_ITEM_LIST_LENGTH': 50,\n",
       " 'POSITION_FIELD': 'position_id',\n",
       " 'HEAD_ENTITY_ID_FIELD': 'head_id',\n",
       " 'TAIL_ENTITY_ID_FIELD': 'tail_id',\n",
       " 'RELATION_ID_FIELD': 'relation_id',\n",
       " 'ENTITY_ID_FIELD': 'entity_id',\n",
       " 'benchmark_filename': ['train', 'test'],\n",
       " 'MODEL_TYPE': <ModelType.SEQUENTIAL: 2>,\n",
       " 'dataset': 'retailrocket-sess',\n",
       " 'model': 'GRU4Rec',\n",
       " 'MODEL_INPUT_TYPE': <InputType.POINTWISE: 1>,\n",
       " 'eval_type': <EvaluatorType.RANKING: 1>,\n",
       " 'device': device(type='cuda'),\n",
       " 'train_neg_sample_args': {'strategy': 'none'},\n",
       " 'eval_neg_sample_args': {'strategy': 'full', 'distribution': 'uniform'}}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = Config(model=args.model, dataset=f'{args.dataset}', config_dict=config_dict_sess)\n",
    "config.final_config_dict['data_path'] = os.path.join(os.path.dirname(os.getcwd()),config.final_config_dict['data_path'])\n",
    "config.final_config_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;35mretailrocket-sess\u001b[0m\n",
       "\u001b[1;34mThe number of users\u001b[0m: 749606\n",
       "\u001b[1;34mAverage actions of users\u001b[0m: 1.037926641364452\n",
       "\u001b[1;34mThe number of items\u001b[0m: 56073\n",
       "\u001b[1;34mAverage actions of items\u001b[0m: 15.913014132902461\n",
       "\u001b[1;34mThe number of inters\u001b[0m: 778035\n",
       "\u001b[1;34mThe sparsity of the dataset\u001b[0m: 99.99814897498487%\n",
       "\u001b[1;34mRemain Fields\u001b[0m: ['session_id', 'item_id_list', 'item_id', 'item_length']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# called from the main script and performs a set of operations to load the .inter file to dataframe\n",
    "retailrocket_sess = create_dataset(config)\n",
    "retailrocket_sess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the statistics is different than what's described above. its expected as we broke sessions to shorter ones, but I'd expect the number of items to be similar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_id</th>\n",
       "      <th>item_id_list</th>\n",
       "      <th>item_id</th>\n",
       "      <th>item_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[1, 1, 4, 2, 3, 3, 2]</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>[1, 1, 4, 2, 3, 3]</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>[1, 1, 4, 2, 3]</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>[1, 1, 4, 2]</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>[1, 1, 4]</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   session_id           item_id_list  item_id  item_length\n",
       "0           1  [1, 1, 4, 2, 3, 3, 2]        1            7\n",
       "1           2     [1, 1, 4, 2, 3, 3]        2            6\n",
       "2           3        [1, 1, 4, 2, 3]        3            5\n",
       "3           4           [1, 1, 4, 2]        3            4\n",
       "4           5              [1, 1, 4]        2            3"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retailrocket_sess_inter_df=retailrocket_sess.inter_feat\n",
    "retailrocket_sess_inter_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RSC15\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## session-rec\n",
    "the preprocess config file is as follows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "/home/gkoren2/study/git/guyk1971/session-rec/conf/myconf/prep_rsc15_sb_s.yml\n",
    "```yml\n",
    "type: single # single|window\n",
    "mode: session_based # session_based | session_aware\n",
    "preprocessor: rsc15 # dataset (folder) name\n",
    "data:\n",
    "  folder: /home/gkoren2/datasets/recsys/seq_recsys_datasets/rsc15/raw/\n",
    "  prefix: rsc15-clicks\n",
    "\n",
    "filter:\n",
    "  min_item_support: 5\n",
    "  min_session_length: 2\n",
    "\n",
    "params:\n",
    "  days_test: 7\n",
    "\n",
    "output:\n",
    "  folder: /home/gkoren2/datasets/recsys/seq_recsys_datasets/rsc15/single/\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rsc15-clicks_test.txt',\n",
       " 'rsc15-clicks_train_valid.txt',\n",
       " 'rsc15-clicks_train_tr.txt',\n",
       " 'rsc15-clicks_train_full.txt']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prep_srec_path = '/home/gkoren2/datasets/recsys/seq_recsys_datasets/rsc15/single'\n",
    "os.listdir(prep_srec_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we want to do the following conversion:\n",
    "- `rsc15-clicks_train_full.txt` --> `rsc15-sess.train.inter`\n",
    "- `rsc15-clicks_test.txt` --> `rsc15-sess.test.inter`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating ./rsc15-sess.train.inter:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67eb6a6701a7420f96b7be837236d2c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7802144 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating ./rsc15-sess.test.inter:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fb068d70f6a4268a3c377702dcb95c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/172361 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "srec_train_filename='rsc15-clicks_train_full'\n",
    "inter_train_filename='./rsc15-sess.train.inter'\n",
    "\n",
    "srec_test_filename='rsc15-clicks_test'\n",
    "inter_test_filename='./rsc15-sess.test.inter'\n",
    "\n",
    "convert_srec_to_recbole(srec_train_filename,srec_test_filename,inter_train_filename,inter_test_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RecBole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Arguments(model='GRU4Rec', dataset='rsc15-sess', validation='False', valid_portion=0.1)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args = Arguments(dataset='rsc15-sess')\n",
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gpu_id': 0,\n",
       " 'use_gpu': True,\n",
       " 'seed': 2020,\n",
       " 'state': 'INFO',\n",
       " 'reproducibility': True,\n",
       " 'data_path': '/home/gkoren2/study/git/guyk1971/RecBole/dataset/rsc15-sess',\n",
       " 'checkpoint_dir': 'saved',\n",
       " 'show_progress': True,\n",
       " 'save_dataset': False,\n",
       " 'dataset_save_path': None,\n",
       " 'save_dataloaders': False,\n",
       " 'dataloaders_save_path': None,\n",
       " 'log_wandb': False,\n",
       " 'wandb_project': 'recbole',\n",
       " 'epochs': 300,\n",
       " 'train_batch_size': 2048,\n",
       " 'learner': 'adam',\n",
       " 'learning_rate': 0.001,\n",
       " 'neg_sampling': None,\n",
       " 'eval_step': 1,\n",
       " 'stopping_step': 10,\n",
       " 'clip_grad_norm': None,\n",
       " 'weight_decay': 0.0,\n",
       " 'loss_decimal_place': 4,\n",
       " 'require_pow': False,\n",
       " 'eval_args': {'split': {'LS': 'valid_and_test'},\n",
       "  'order': 'TO',\n",
       "  'mode': 'full',\n",
       "  'group_by': 'user'},\n",
       " 'repeatable': True,\n",
       " 'metrics': ['Recall', 'MRR'],\n",
       " 'topk': [20],\n",
       " 'valid_metric': 'MRR@20',\n",
       " 'valid_metric_bigger': True,\n",
       " 'eval_batch_size': 4096,\n",
       " 'metric_decimal_place': 4,\n",
       " 'embedding_size': 64,\n",
       " 'hidden_size': 128,\n",
       " 'num_layers': 1,\n",
       " 'dropout_prob': 0.3,\n",
       " 'loss_type': 'CE',\n",
       " 'field_separator': '\\t',\n",
       " 'seq_separator': ' ',\n",
       " 'USER_ID_FIELD': 'session_id',\n",
       " 'ITEM_ID_FIELD': 'item_id',\n",
       " 'RATING_FIELD': 'rating',\n",
       " 'TIME_FIELD': 'timestamp',\n",
       " 'seq_len': None,\n",
       " 'LABEL_FIELD': 'label',\n",
       " 'threshold': None,\n",
       " 'NEG_PREFIX': 'neg_',\n",
       " 'load_col': None,\n",
       " 'unload_col': None,\n",
       " 'unused_col': None,\n",
       " 'additional_feat_suffix': None,\n",
       " 'rm_dup_inter': None,\n",
       " 'val_interval': None,\n",
       " 'filter_inter_by_user_or_item': True,\n",
       " 'user_inter_num_interval': '[0,inf)',\n",
       " 'item_inter_num_interval': '[0,inf)',\n",
       " 'alias_of_user_id': None,\n",
       " 'alias_of_item_id': ['item_id_list'],\n",
       " 'alias_of_entity_id': None,\n",
       " 'alias_of_relation_id': None,\n",
       " 'preload_weight': None,\n",
       " 'normalize_field': None,\n",
       " 'normalize_all': None,\n",
       " 'ITEM_LIST_LENGTH_FIELD': 'item_length',\n",
       " 'LIST_SUFFIX': '_list',\n",
       " 'MAX_ITEM_LIST_LENGTH': 50,\n",
       " 'POSITION_FIELD': 'position_id',\n",
       " 'HEAD_ENTITY_ID_FIELD': 'head_id',\n",
       " 'TAIL_ENTITY_ID_FIELD': 'tail_id',\n",
       " 'RELATION_ID_FIELD': 'relation_id',\n",
       " 'ENTITY_ID_FIELD': 'entity_id',\n",
       " 'benchmark_filename': ['train', 'test'],\n",
       " 'MODEL_TYPE': <ModelType.SEQUENTIAL: 2>,\n",
       " 'dataset': 'rsc15-sess',\n",
       " 'model': 'GRU4Rec',\n",
       " 'MODEL_INPUT_TYPE': <InputType.POINTWISE: 1>,\n",
       " 'eval_type': <EvaluatorType.RANKING: 1>,\n",
       " 'device': device(type='cuda'),\n",
       " 'train_neg_sample_args': {'strategy': 'none'},\n",
       " 'eval_neg_sample_args': {'strategy': 'full', 'distribution': 'uniform'}}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = Config(model=args.model, dataset=f'{args.dataset}', config_dict=config_dict_sess)\n",
    "config.final_config_dict['data_path'] = os.path.join(os.path.dirname(os.getcwd()),config.final_config_dict['data_path'])\n",
    "config.final_config_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;35mrsc15-sess\u001b[0m\n",
       "\u001b[1;34mThe number of users\u001b[0m: 23156029\n",
       "\u001b[1;34mAverage actions of users\u001b[0m: 1.0224371381827662\n",
       "\u001b[1;34mThe number of items\u001b[0m: 58302\n",
       "\u001b[1;34mAverage actions of items\u001b[0m: 634.3769727499263\n",
       "\u001b[1;34mThe number of inters\u001b[0m: 23675583\n",
       "\u001b[1;34mThe sparsity of the dataset\u001b[0m: 99.9982463087132%\n",
       "\u001b[1;34mRemain Fields\u001b[0m: ['session_id', 'item_id_list', 'item_id', 'item_length']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# called from the main script and performs a set of operations to load the .inter file to dataframe\n",
    "rsc15_sess = create_dataset(config)\n",
    "rsc15_sess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_id</th>\n",
       "      <th>item_id_list</th>\n",
       "      <th>item_id</th>\n",
       "      <th>item_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[736, 3, 2]</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>[736, 3]</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>[736]</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>[8, 8, 7, 6, 5]</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>[8, 8, 7, 6]</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   session_id     item_id_list  item_id  item_length\n",
       "0           1      [736, 3, 2]        1            3\n",
       "1           2         [736, 3]        2            2\n",
       "2           3            [736]        3            1\n",
       "3           4  [8, 8, 7, 6, 5]        4            5\n",
       "4           5     [8, 8, 7, 6]        5            4"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rsc15_sess_inter_df=rsc15_sess.inter_feat\n",
    "rsc15_sess_inter_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('recbole')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bc0fd1abc2602ec1b3e4206595ab69b0e3cf447ced07bd62f4679a23079f293a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
